{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"CLASS_RND_Aubeuf.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"7tTNc0FRj8Uo"},"source":["# <center>Machine Learning</center>\n","\n","## Classification MNIST à l'aide d'un réseau de neurones dense\n","### Clément AUBEUF"]},{"cell_type":"markdown","metadata":{"id":"rIo8uTVasE2f"},"source":["----\n","\n","<a\n","  target=\"_blank\" href=\"https://colab.research.google.com/drive/10w9E1whCPMZZposk2vru9cYNEA3CavuG\"> \n","  <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> \n","  Ouvrir dans Google Colab\n","</a>\n","\n","----"]},{"cell_type":"markdown","metadata":{"id":"96hZKVcsj8Up"},"source":["### Importation de bibliothèques"]},{"cell_type":"code","metadata":{"id":"tg7jZyOdl6A5"},"source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GaZ_gV1rNL_l"},"source":["### Importation de la banque de données MNIST fashion"]},{"cell_type":"code","metadata":{"id":"ffcm7Ay0l6DU"},"source":["dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n","train_dataset, test_dataset = dataset['train'], dataset['test']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Da_CTXrhl6FR"},"source":["class_names = metadata.features['label'].names\n","\n","# On affiche les étiquettes des vêtements disponibles\n","print(\"Labels des vêtements : {}\".format(class_names))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GkCCQCYfNY3R"},"source":["On importe la banque de données MNIST fashion (les images de vêtements) ainsi que leurs étiquettes (pullover, shirt etc ...)"]},{"cell_type":"markdown","metadata":{"id":"0_6lQXxgNkDW"},"source":["### Séparation des données"]},{"cell_type":"markdown","metadata":{"id":"LyTLlspdNrRJ"},"source":["La majeure partie servira à entrainer le modèle, tandis que le reste des données servira de test à notre modèle"]},{"cell_type":"code","metadata":{"id":"OT3nR9cXl6HN"},"source":["num_train_examples = metadata.splits['train'].num_examples\n","num_test_examples = metadata.splits['test'].num_examples\n","\n","print(\"Nombre d'exemples pour l'entrainement : {}\".format(num_train_examples))\n","print(\"Nombre d'exemples pour le test final : {}\".format(num_test_examples))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IhIBOHswOW6U"},"source":["### Normalisation des données"]},{"cell_type":"markdown","metadata":{"id":"ATOBbRjoOaAp"},"source":["Les images sont actuellement codées avec des valeurs comprises entre 0 et 255. Pour améliorer l'apprentissage du modèle, on préfèrera les codées dans une intervalle [0,1]."]},{"cell_type":"code","metadata":{"id":"PLUiNehHl6JW"},"source":["def normalize(images, labels):\n","  images = tf.cast(images, tf.float32)\n","  images /= 255\n","  return images, labels\n","\n","# On applique la fonction de normalisation aux images d'entrainements et de test\n","train_dataset =  train_dataset.map(normalize)\n","test_dataset  =  test_dataset.map(normalize)\n","\n","# Et on place les images dans le cache plutôt que sur le disque (ce qui améliore la rapidité d'entrainement du modèle)\n","train_dataset =  train_dataset.cache()\n","test_dataset  =  test_dataset.cache()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4lhiI1ZYQB_y"},"source":["### Visualisation des données actuelles"]},{"cell_type":"code","metadata":{"id":"Lt7bMe8hl6Pc"},"source":["# Pour afficher une image, on doit retirer les couleurs : on utilise reshape afin de retirer la 3e dimension\n","# On passe alors d'une image dimension/dimension/couleur à une image dimension/dimension\n","for image, label in test_dataset.take(1):\n","  break\n","image = image.numpy().reshape((28,28))\n","\n","# Et on affiche l'image\n","plt.figure()\n","plt.imshow(image, cmap=plt.cm.binary)\n","plt.grid(False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z7K-FxY_QGdw"},"source":["On peut appliquer ce code de manière récursive : celà permet d'afficher plusieures images."]},{"cell_type":"code","metadata":{"id":"nNn-g4j7l6Ri"},"source":["# On dimensionne le tableau qui contiendra nos images\n","plt.figure(figsize=(10,10))\n","\n","# Et on applique le code utilisé précédemment\n","for i, (image, label) in enumerate(test_dataset.take(25)):\n","    image = image.numpy().reshape((28,28))\n","    # On dimensionne les images afin de les rendre plus petites pour en afficher plus\n","    plt.subplot(5,5,i+1)\n","    # On retire les valeurs des axes X et Y (la dimension des images, qui ne nous interesse pas ici)\n","    plt.xticks([])\n","    plt.yticks([])\n","    # On retire la grille\n","    plt.grid(False)\n","    # On affiche l'image\n","    plt.imshow(image, cmap=plt.cm.binary)\n","    # Et on ajoute l'étiquette correspondant au vêtement\n","    plt.xlabel(class_names[label])\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pfSaO-i9RL8D"},"source":["### Création du modèle"]},{"cell_type":"code","metadata":{"id":"9kS50prPl6T2"},"source":["# On crée notre modèle en utilisant un réseau de neurones dense\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n","    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n","    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CuV_038JRpgh"},"source":["On distingue ici trois layers : <br>\n","- un layer d'entrée (layers.Flatten) qui transforme l'image 2D (dimensions et couleur) en image 1D (dimensions) \n","- un layer caché composé de 128 neurones et utilisant la méthode relu \n","- un layer de sortie composé de 10 noeuds (qui correspondent aux 10 types de vêtements)"]},{"cell_type":"code","metadata":{"id":"DlJMjfj7l6Vz"},"source":["# Notre modèle a encore besoin de quelques paramètres avant d'être entrainé : \n","# on définit la méthode d'optimisation, la fonction de perte et le paramètre sur lequel le modèle doit s'entrainer.\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","              metrics=['accuracy'])\n","\n","# metrics=['accuracy'] signifie que le modèle classera ces résultats en fonction de sa précision (est ce que le vêtement est bien ou mal nommé ?)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zSrtdehsTeRT"},"source":["### Entrainement du modèle"]},{"cell_type":"code","metadata":{"id":"QolPmLK2l6YM"},"source":["# On définit le comportement que le programme doit suivre pour son apprentissage\n","lots_img = 32\n","train_dataset = train_dataset.cache().repeat().shuffle(num_train_examples).batch(lots_img)\n","test_dataset = test_dataset.cache().batch(lots_img)\n","\n","# .cache = place les données dans le cache\n","# .repeat = le modèle répètera cette opération à l'infini\n","# .shuffle = mélange les données (en fonction du nombre de données)\n","# .batch = le modèle apprend par lot de 32 images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qAVvcXPXT82T"},"source":["# Et on entraine le modèle\n","model.fit(train_dataset, epochs=3, steps_per_epoch=math.ceil(num_train_examples/lots_img))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jx_s-za2U0JA"},"source":["### Précision du modèle"]},{"cell_type":"code","metadata":{"id":"IETcycKFl6aL"},"source":["# On peut tester la précision du modèle sur les données de test\n","# Afin de gagner du temps, nous n'utiliserons qu'une fraction de ces données (ici 10.000/50, soit 200 données)\n","test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/50))\n","\n","print('Précision du modèle :', int(round(test_accuracy, 2)*100),'%')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Qpj_ICEWDI3"},"source":["### Application du modèle"]},{"cell_type":"markdown","metadata":{"id":"gGKQWth7gyUX"},"source":["Appliquons notre modèle à un lot de vêtements :"]},{"cell_type":"code","metadata":{"id":"Zp9GvNial6ci"},"source":["# On applique le modèle à un lot d'images : take(1)\n","# Ce lot est constitué de 32 images (définit précédemment)\n","for test_images, test_labels in test_dataset.take(1):\n","  test_images = test_images.numpy()\n","  test_labels = test_labels.numpy()\n","  predictions = model.predict(test_images)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v8P1lYbIg75P"},"source":["----"]},{"cell_type":"markdown","metadata":{"id":"1bs5zSk8d0F1"},"source":["On teste le vêtement à l'index 20 :"]},{"cell_type":"code","metadata":{"id":"k9UjzdKRWL9L"},"source":["print(predictions[20])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3-L00SgEW4I5"},"source":["On obtient un tableau contenant la probabilité de chaque étiquette (tshirt, pull, shoes ...) pour ce vêtement."]},{"cell_type":"code","metadata":{"id":"3b5v3AbwWLYK"},"source":["# On isole la probabilité la plus grande\n","print('Probabilité la plus haute : étiquette de vêtement numéro', np.argmax(predictions[20]))\n","\n","# et on vérifie la réponse correcte\n","print('Réponse correcte : étiquette de vêtement numéro', test_labels[20])\n","\n","# Ce qui correspond à\n","print('Vêtement détecté :', class_names[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pQjwUHazeEsj"},"source":["Le vêtement à l'index 20 est donc bien un T-shirt : notre modèle ne s'est pas trompé !"]},{"cell_type":"markdown","metadata":{"id":"GbnJmDSFZIpC"},"source":["### Affichage des résultats"]},{"cell_type":"code","metadata":{"id":"cxXbwm7jl6et"},"source":["# On définit la fonction permettant d'afficher le vêtement en utilisant un paramètre i (qui correspond à l'index du vêtement)\n","# Note : cette fonction est très similaire à celle utilisée en début de page pour afficher le vêtement\n","def plot_image(i, predictions_array, true_labels, images):\n","  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","  plt.imshow(img[...,0], cmap=plt.cm.binary)\n","  predicted_label = np.argmax(predictions_array)\n","\n","  # En fonction de la prédiction, le nom du vêtement s'affiche en vert (correct) ou en rouge\n","  if predicted_label == true_label:\n","    color = 'green'\n","  else:\n","    color = 'red'\n","  \n","  # Et on ajoute l'étiquette du vêtement\n","  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n","                                100*np.max(predictions_array),\n","                                class_names[true_label]),\n","                                color=color)\n","\n","# On crée une seconde fonction qui permet d'afficher les probabilités sous forme de graphique, toujours en fonction de i\n","def plot_value_array(i, predictions_array, true_label):\n","  predictions_array, true_label = predictions_array[i], true_label[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","  # Toutes les prédictions apparaitront en vert clair\n","  thisplot = plt.bar(range(10), predictions_array, color=\"lightgreen\")\n","  plt.ylim([0, 1]) \n","  predicted_label = np.argmax(predictions_array)\n","  \n","  # On superpose les barres du graph :\n","  # - si le résultat est bon, une barre verte foncée sera visible\n","  # - sinon, nous verrons une barre verte (le bon résultat) et une barre rouge (le résultat prédit)\n","  thisplot[predicted_label].set_color('red')\n","  thisplot[true_label].set_color('green')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cL5gK9B0barp"},"source":["La mise en forme des résultats est définie, il ne reste plus qu'à tester !"]},{"cell_type":"markdown","metadata":{"id":"9cBXwsDwepmr"},"source":["----"]},{"cell_type":"markdown","metadata":{"id":"XdQvzJDpetaj"},"source":["Testons le vêtement à l'index 5."]},{"cell_type":"code","metadata":{"id":"hF5s1tCjl6g4"},"source":["i = 5\n","\n","# On affiche le graph\n","plt.figure(figsize=(15,3))\n","plt.subplot(1,2,1)\n","\n","# l'image\n","plot_image(i, predictions, test_labels, test_images)\n","plt.subplot(1,2,2)\n","\n","# on place les résultats sur le graphique\n","plot_value_array(i, predictions, test_labels)\n","\n","# Et on affiche les catégories du graphique\n","_ = plt.xticks(range(10), class_names, rotation=45)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YSqs35FjenIp"},"source":["----"]},{"cell_type":"markdown","metadata":{"id":"tZhFo4pLezpC"},"source":["Et le vêtement index 20 ?"]},{"cell_type":"code","metadata":{"id":"uTI8PF2Ll6jH"},"source":["i = 20\n","\n","plt.figure(figsize=(15,3))\n","plt.subplot(1,2,1)\n","\n","plot_image(i, predictions, test_labels, test_images)\n","plt.subplot(1,2,2)\n","\n","plot_value_array(i, predictions, test_labels)\n","_ = plt.xticks(range(10), class_names, rotation=45)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QPpoS4YfdGD-"},"source":["----"]},{"cell_type":"markdown","metadata":{"id":"ds_qJLp6eb0K"},"source":["Enfin, on peut afficher plusieurs résultats d'un seul coup :"]},{"cell_type":"code","metadata":{"id":"zIAHB-Qol6lR"},"source":["nbr_lignes = 3\n","nbr_col = 3\n","nbr_imgs = nbr_lignes * nbr_col\n","\n","plt.figure(figsize=(16, 8))\n","for i in range(nbr_imgs):\n","  # On affiche l'image et sa prédiction\n","  plt.subplot(nbr_lignes, 2*nbr_col, 2*i+1)\n","  plot_image(i, predictions, test_labels, test_images)\n","  # On affiche le graphique de prédictions\n","  plt.subplot(nbr_lignes, 2*nbr_col, 2*i+2)  \n","  plot_value_array(i, predictions, test_labels)"],"execution_count":null,"outputs":[]}]}